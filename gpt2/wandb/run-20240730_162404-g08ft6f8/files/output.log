
using device: cuda
loaded: 11909059
1 epoch = 5814 batches
step: 0, loss: (10.862091064453125,) dt: 691.06ms
step: 1, loss: (10.465615272521973,) dt: 709.49ms
step: 2, loss: (10.266549110412598,) dt: 348.79ms
step: 3, loss: (10.263855934143066,) dt: 351.69ms
step: 4, loss: (10.032200813293457,) dt: 348.58ms
step: 5, loss: (9.889786720275879,) dt: 363.38ms
step: 6, loss: (9.863730430603027,) dt: 351.59ms
step: 7, loss: (11.568077087402344,) dt: 351.16ms
step: 8, loss: (9.648500442504883,) dt: 352.22ms
step: 9, loss: (9.719942092895508,) dt: 360.28ms
step: 10, loss: (9.51508617401123,) dt: 351.12ms
step: 11, loss: (9.236835479736328,) dt: 366.38ms
step: 12, loss: (9.274643898010254,) dt: 351.21ms
step: 13, loss: (9.224983215332031,) dt: 350.50ms
step: 14, loss: (9.020520210266113,) dt: 395.48ms
step: 15, loss: (9.088462829589844,) dt: 355.55ms
step: 16, loss: (8.8416109085083,) dt: 355.10ms
step: 17, loss: (8.82919979095459,) dt: 377.91ms
step: 18, loss: (8.497542381286621,) dt: 420.90ms
step: 19, loss: (8.676976203918457,) dt: 367.31ms
step: 20, loss: (8.51862621307373,) dt: 362.18ms
step: 21, loss: (8.337385177612305,) dt: 404.99ms
step: 22, loss: (8.20267105102539,) dt: 397.76ms
step: 23, loss: (8.162862777709961,) dt: 390.76ms
step: 24, loss: (8.074243545532227,) dt: 413.13ms
step: 25, loss: (8.091449737548828,) dt: 414.96ms
step: 26, loss: (7.762723922729492,) dt: 379.49ms
step: 27, loss: (7.717462539672852,) dt: 370.41ms
step: 28, loss: (7.432534217834473,) dt: 392.27ms
step: 29, loss: (7.594531536102295,) dt: 380.61ms
step: 30, loss: (7.307946681976318,) dt: 380.83ms
step: 31, loss: (7.30579948425293,) dt: 382.80ms
step: 32, loss: (7.347105503082275,) dt: 390.82ms
step: 33, loss: (7.032083511352539,) dt: 385.79ms
step: 34, loss: (7.2508697509765625,) dt: 370.66ms
step: 35, loss: (7.144075870513916,) dt: 378.56ms
step: 36, loss: (6.754389762878418,) dt: 378.10ms
step: 37, loss: (6.896826267242432,) dt: 363.48ms
step: 38, loss: (7.15470027923584,) dt: 364.55ms
step: 39, loss: (7.0049238204956055,) dt: 373.21ms
step: 40, loss: (6.618908882141113,) dt: 365.64ms
step: 41, loss: (6.7552714347839355,) dt: 372.10ms
step: 42, loss: (6.776028156280518,) dt: 375.00ms
step: 43, loss: (6.570985317230225,) dt: 373.54ms
step: 44, loss: (6.6130266189575195,) dt: 372.63ms
step: 45, loss: (6.540511608123779,) dt: 370.47ms
step: 46, loss: (6.456937789916992,) dt: 363.37ms
step: 47, loss: (6.394719123840332,) dt: 353.79ms
step: 48, loss: (6.671028137207031,) dt: 353.70ms
step: 49, loss: (6.45578145980835,) dt: 372.54ms
>  Hello I'm a language model, I'm me,, [ you] You they, You I [ < on, a You and the me,]in' I shitse I' in me't, I on it, that out the]
>  Hello I'm a language model,> upk I I'm a You, youVer up I And ain't I I get I niggas You niggas I be the love me get, I'in' but You ain't don
>  Hello I'm a language model,, I [orusEmb withorusOS I that in the on you you, I, I'm say,, (, I'm get, I, don't,, I, I and with, I [
>  Hello I'm a language model, IVerB't, I, get the You, I to it that the ] don't up, n know,, don't ain myEmbEmb I I You,se be that my, I and
>  Hello I'm a language model, they with I that theorus [ < it up to I that < don't on the say I, you it, up, niggas, on of, ain't] with on I'm out,